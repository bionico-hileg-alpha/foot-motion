{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>acc_rf_x</th>\n",
       "      <th>acc_rf_y</th>\n",
       "      <th>acc_rf_z</th>\n",
       "      <th>gyro_rf_x</th>\n",
       "      <th>gyro_rf_y</th>\n",
       "      <th>gyro_rf_z</th>\n",
       "      <th>acc_rs_x</th>\n",
       "      <th>acc_rs_y</th>\n",
       "      <th>acc_rs_z</th>\n",
       "      <th>...</th>\n",
       "      <th>gyro_lf_z</th>\n",
       "      <th>acc_ls_x</th>\n",
       "      <th>acc_ls_y</th>\n",
       "      <th>acc_ls_z</th>\n",
       "      <th>gyro_ls_x</th>\n",
       "      <th>gyro_ls_y</th>\n",
       "      <th>gyro_ls_z</th>\n",
       "      <th>EMG_r</th>\n",
       "      <th>EMG_l</th>\n",
       "      <th>act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.784901e+03</td>\n",
       "      <td>-1.108880e+04</td>\n",
       "      <td>-5.221161e+03</td>\n",
       "      <td>1.172899e+04</td>\n",
       "      <td>-2.925065e+02</td>\n",
       "      <td>-2.033364e+02</td>\n",
       "      <td>-1.975741e+02</td>\n",
       "      <td>-1.558741e+04</td>\n",
       "      <td>-1.338632e+03</td>\n",
       "      <td>-4.212122e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.122504e+01</td>\n",
       "      <td>-1.551512e+04</td>\n",
       "      <td>1.890316e+03</td>\n",
       "      <td>-4.590912e+03</td>\n",
       "      <td>1.146802e+02</td>\n",
       "      <td>1.679824e+02</td>\n",
       "      <td>2.220078e+03</td>\n",
       "      <td>1.255448e+02</td>\n",
       "      <td>1.268707e+02</td>\n",
       "      <td>5.235844e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.964696e+03</td>\n",
       "      <td>9.137809e+03</td>\n",
       "      <td>8.290712e+03</td>\n",
       "      <td>9.045460e+03</td>\n",
       "      <td>5.254802e+03</td>\n",
       "      <td>1.112977e+04</td>\n",
       "      <td>8.481892e+03</td>\n",
       "      <td>6.409830e+03</td>\n",
       "      <td>5.790768e+03</td>\n",
       "      <td>7.833801e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>8.115045e+03</td>\n",
       "      <td>6.591816e+03</td>\n",
       "      <td>5.528829e+03</td>\n",
       "      <td>7.998856e+03</td>\n",
       "      <td>5.060425e+03</td>\n",
       "      <td>9.327429e+03</td>\n",
       "      <td>2.967224e+06</td>\n",
       "      <td>1.915148e+01</td>\n",
       "      <td>2.130896e+01</td>\n",
       "      <td>3.843590e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.276800e+04</td>\n",
       "      <td>-3.276800e+04</td>\n",
       "      <td>-3.276800e+04</td>\n",
       "      <td>-3.276800e+04</td>\n",
       "      <td>-3.276800e+04</td>\n",
       "      <td>-3.276800e+04</td>\n",
       "      <td>-3.276800e+04</td>\n",
       "      <td>-3.276800e+04</td>\n",
       "      <td>-3.276800e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.276800e+04</td>\n",
       "      <td>-3.276800e+04</td>\n",
       "      <td>-3.276800e+04</td>\n",
       "      <td>-3.276800e+04</td>\n",
       "      <td>-3.276800e+04</td>\n",
       "      <td>-3.276800e+04</td>\n",
       "      <td>-3.276800e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.630000e+02</td>\n",
       "      <td>-1.170800e+04</td>\n",
       "      <td>-7.932000e+03</td>\n",
       "      <td>1.111600e+04</td>\n",
       "      <td>-2.300000e+02</td>\n",
       "      <td>-7.600000e+01</td>\n",
       "      <td>-2.090000e+02</td>\n",
       "      <td>-1.668000e+04</td>\n",
       "      <td>-4.048000e+03</td>\n",
       "      <td>-7.036000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.140000e+02</td>\n",
       "      <td>-1.671200e+04</td>\n",
       "      <td>-7.600000e+02</td>\n",
       "      <td>-7.652000e+03</td>\n",
       "      <td>-1.710000e+02</td>\n",
       "      <td>-9.200000e+01</td>\n",
       "      <td>-1.100000e+02</td>\n",
       "      <td>1.220000e+02</td>\n",
       "      <td>1.230000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.892000e+03</td>\n",
       "      <td>-9.204000e+03</td>\n",
       "      <td>-4.632000e+03</td>\n",
       "      <td>1.274800e+04</td>\n",
       "      <td>-1.200000e+01</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>-2.800000e+01</td>\n",
       "      <td>-1.579200e+04</td>\n",
       "      <td>-8.680000e+02</td>\n",
       "      <td>-3.360000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.370000e+02</td>\n",
       "      <td>-1.585600e+04</td>\n",
       "      <td>1.808000e+03</td>\n",
       "      <td>-3.456000e+03</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>1.260000e+02</td>\n",
       "      <td>1.270000e+02</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.586000e+03</td>\n",
       "      <td>-7.228000e+03</td>\n",
       "      <td>-2.736000e+03</td>\n",
       "      <td>1.407600e+04</td>\n",
       "      <td>1.770000e+02</td>\n",
       "      <td>6.260000e+02</td>\n",
       "      <td>5.430000e+02</td>\n",
       "      <td>-1.378400e+04</td>\n",
       "      <td>1.612000e+03</td>\n",
       "      <td>-8.560000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.200000e+01</td>\n",
       "      <td>-1.372800e+04</td>\n",
       "      <td>4.520000e+03</td>\n",
       "      <td>-1.008000e+03</td>\n",
       "      <td>5.300000e+02</td>\n",
       "      <td>1.431000e+03</td>\n",
       "      <td>3.080000e+02</td>\n",
       "      <td>1.290000e+02</td>\n",
       "      <td>1.320000e+02</td>\n",
       "      <td>8.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.115400e+04</td>\n",
       "      <td>3.276700e+04</td>\n",
       "      <td>3.276700e+04</td>\n",
       "      <td>3.276700e+04</td>\n",
       "      <td>3.276700e+04</td>\n",
       "      <td>3.276700e+04</td>\n",
       "      <td>3.276700e+04</td>\n",
       "      <td>3.276700e+04</td>\n",
       "      <td>3.276700e+04</td>\n",
       "      <td>3.276700e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.276700e+04</td>\n",
       "      <td>1.306072e+06</td>\n",
       "      <td>3.276700e+04</td>\n",
       "      <td>3.276700e+04</td>\n",
       "      <td>3.276700e+04</td>\n",
       "      <td>9.172000e+04</td>\n",
       "      <td>4.312047e+09</td>\n",
       "      <td>2.540000e+02</td>\n",
       "      <td>2.540000e+02</td>\n",
       "      <td>1.200000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp      acc_rf_x      acc_rf_y      acc_rf_z     gyro_rf_x  \\\n",
       "count  2.111869e+06  2.111869e+06  2.111869e+06  2.111869e+06  2.111869e+06   \n",
       "mean   2.784901e+03 -1.108880e+04 -5.221161e+03  1.172899e+04 -2.925065e+02   \n",
       "std    2.964696e+03  9.137809e+03  8.290712e+03  9.045460e+03  5.254802e+03   \n",
       "min    0.000000e+00 -3.276800e+04 -3.276800e+04 -3.276800e+04 -3.276800e+04   \n",
       "25%    8.630000e+02 -1.170800e+04 -7.932000e+03  1.111600e+04 -2.300000e+02   \n",
       "50%    1.892000e+03 -9.204000e+03 -4.632000e+03  1.274800e+04 -1.200000e+01   \n",
       "75%    3.586000e+03 -7.228000e+03 -2.736000e+03  1.407600e+04  1.770000e+02   \n",
       "max    2.115400e+04  3.276700e+04  3.276700e+04  3.276700e+04  3.276700e+04   \n",
       "\n",
       "          gyro_rf_y     gyro_rf_z      acc_rs_x      acc_rs_y      acc_rs_z  \\\n",
       "count  2.111869e+06  2.111869e+06  2.111869e+06  2.111869e+06  2.111869e+06   \n",
       "mean  -2.033364e+02 -1.975741e+02 -1.558741e+04 -1.338632e+03 -4.212122e+03   \n",
       "std    1.112977e+04  8.481892e+03  6.409830e+03  5.790768e+03  7.833801e+03   \n",
       "min   -3.276800e+04 -3.276800e+04 -3.276800e+04 -3.276800e+04 -3.276800e+04   \n",
       "25%   -7.600000e+01 -2.090000e+02 -1.668000e+04 -4.048000e+03 -7.036000e+03   \n",
       "50%    2.300000e+01 -2.800000e+01 -1.579200e+04 -8.680000e+02 -3.360000e+03   \n",
       "75%    6.260000e+02  5.430000e+02 -1.378400e+04  1.612000e+03 -8.560000e+02   \n",
       "max    3.276700e+04  3.276700e+04  3.276700e+04  3.276700e+04  3.276700e+04   \n",
       "\n",
       "           ...          gyro_lf_z      acc_ls_x      acc_ls_y      acc_ls_z  \\\n",
       "count      ...       2.111869e+06  2.111869e+06  2.111869e+06  2.111869e+06   \n",
       "mean       ...      -9.122504e+01 -1.551512e+04  1.890316e+03 -4.590912e+03   \n",
       "std        ...       8.115045e+03  6.591816e+03  5.528829e+03  7.998856e+03   \n",
       "min        ...      -3.276800e+04 -3.276800e+04 -3.276800e+04 -3.276800e+04   \n",
       "25%        ...      -7.140000e+02 -1.671200e+04 -7.600000e+02 -7.652000e+03   \n",
       "50%        ...      -1.370000e+02 -1.585600e+04  1.808000e+03 -3.456000e+03   \n",
       "75%        ...      -1.200000e+01 -1.372800e+04  4.520000e+03 -1.008000e+03   \n",
       "max        ...       3.276700e+04  1.306072e+06  3.276700e+04  3.276700e+04   \n",
       "\n",
       "          gyro_ls_x     gyro_ls_y     gyro_ls_z         EMG_r         EMG_l  \\\n",
       "count  2.111869e+06  2.111869e+06  2.111869e+06  2.111869e+06  2.111869e+06   \n",
       "mean   1.146802e+02  1.679824e+02  2.220078e+03  1.255448e+02  1.268707e+02   \n",
       "std    5.060425e+03  9.327429e+03  2.967224e+06  1.915148e+01  2.130896e+01   \n",
       "min   -3.276800e+04 -3.276800e+04 -3.276800e+04  0.000000e+00  0.000000e+00   \n",
       "25%   -1.710000e+02 -9.200000e+01 -1.100000e+02  1.220000e+02  1.230000e+02   \n",
       "50%    1.900000e+01  0.000000e+00  2.000000e+01  1.260000e+02  1.270000e+02   \n",
       "75%    5.300000e+02  1.431000e+03  3.080000e+02  1.290000e+02  1.320000e+02   \n",
       "max    3.276700e+04  9.172000e+04  4.312047e+09  2.540000e+02  2.540000e+02   \n",
       "\n",
       "                act  \n",
       "count  2.111869e+06  \n",
       "mean   5.235844e+00  \n",
       "std    3.843590e+00  \n",
       "min    1.000000e+00  \n",
       "25%    1.000000e+00  \n",
       "50%    5.000000e+00  \n",
       "75%    8.000000e+00  \n",
       "max    1.200000e+01  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/data/necessary_data.csv')\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_rs_x</th>\n",
       "      <th>acc_rs_y</th>\n",
       "      <th>acc_rs_z</th>\n",
       "      <th>gyro_rs_x</th>\n",
       "      <th>gyro_rs_y</th>\n",
       "      <th>gyro_rs_z</th>\n",
       "      <th>EMG_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "      <td>2.111869e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.621590e-01</td>\n",
       "      <td>4.795814e-01</td>\n",
       "      <td>4.357348e-01</td>\n",
       "      <td>4.980272e-01</td>\n",
       "      <td>5.046632e-01</td>\n",
       "      <td>4.976528e-01</td>\n",
       "      <td>4.942710e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.780774e-02</td>\n",
       "      <td>8.836145e-02</td>\n",
       "      <td>1.195361e-01</td>\n",
       "      <td>9.450305e-02</td>\n",
       "      <td>1.651889e-01</td>\n",
       "      <td>5.989826e-02</td>\n",
       "      <td>7.539953e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.454871e-01</td>\n",
       "      <td>4.382391e-01</td>\n",
       "      <td>3.926452e-01</td>\n",
       "      <td>4.905318e-01</td>\n",
       "      <td>4.982681e-01</td>\n",
       "      <td>4.957656e-01</td>\n",
       "      <td>4.803150e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.590372e-01</td>\n",
       "      <td>4.867628e-01</td>\n",
       "      <td>4.487373e-01</td>\n",
       "      <td>5.000534e-01</td>\n",
       "      <td>5.000076e-01</td>\n",
       "      <td>4.999466e-01</td>\n",
       "      <td>4.960630e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.896773e-01</td>\n",
       "      <td>5.246052e-01</td>\n",
       "      <td>4.869459e-01</td>\n",
       "      <td>5.047532e-01</td>\n",
       "      <td>5.314717e-01</td>\n",
       "      <td>5.030137e-01</td>\n",
       "      <td>5.078740e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           acc_rs_x      acc_rs_y      acc_rs_z     gyro_rs_x     gyro_rs_y  \\\n",
       "count  2.111869e+06  2.111869e+06  2.111869e+06  2.111869e+06  2.111869e+06   \n",
       "mean   2.621590e-01  4.795814e-01  4.357348e-01  4.980272e-01  5.046632e-01   \n",
       "std    9.780774e-02  8.836145e-02  1.195361e-01  9.450305e-02  1.651889e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    2.454871e-01  4.382391e-01  3.926452e-01  4.905318e-01  4.982681e-01   \n",
       "50%    2.590372e-01  4.867628e-01  4.487373e-01  5.000534e-01  5.000076e-01   \n",
       "75%    2.896773e-01  5.246052e-01  4.869459e-01  5.047532e-01  5.314717e-01   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "          gyro_rs_z         EMG_r  \n",
       "count  2.111869e+06  2.111869e+06  \n",
       "mean   4.976528e-01  4.942710e-01  \n",
       "std    5.989826e-02  7.539953e-02  \n",
       "min    0.000000e+00  0.000000e+00  \n",
       "25%    4.957656e-01  4.803150e-01  \n",
       "50%    4.999466e-01  4.960630e-01  \n",
       "75%    5.030137e-01  5.078740e-01  \n",
       "max    1.000000e+00  1.000000e+00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[[\n",
    " 'acc_rs_x',\n",
    " 'acc_rs_y',\n",
    " 'acc_rs_z',\n",
    " 'gyro_rs_x',\n",
    " 'gyro_rs_y',\n",
    " 'gyro_rs_z',\n",
    " 'EMG_r']]\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X.values)\n",
    "DF = pd.DataFrame(x_scaled, columns=list(X))\n",
    "\n",
    "DF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(DF, test_size=0.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_rs_x</th>\n",
       "      <th>acc_rs_y</th>\n",
       "      <th>acc_rs_z</th>\n",
       "      <th>gyro_rs_x</th>\n",
       "      <th>gyro_rs_y</th>\n",
       "      <th>gyro_rs_z</th>\n",
       "      <th>EMG_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1660736</th>\n",
       "      <td>0.251408</td>\n",
       "      <td>0.509102</td>\n",
       "      <td>0.509590</td>\n",
       "      <td>0.499626</td>\n",
       "      <td>0.498985</td>\n",
       "      <td>0.499489</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771477</th>\n",
       "      <td>0.119692</td>\n",
       "      <td>0.435248</td>\n",
       "      <td>0.274540</td>\n",
       "      <td>0.297154</td>\n",
       "      <td>0.829694</td>\n",
       "      <td>0.473777</td>\n",
       "      <td>0.385827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84694</th>\n",
       "      <td>0.253178</td>\n",
       "      <td>0.471687</td>\n",
       "      <td>0.481453</td>\n",
       "      <td>0.499931</td>\n",
       "      <td>0.499901</td>\n",
       "      <td>0.499138</td>\n",
       "      <td>0.476378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934543</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210330</td>\n",
       "      <td>0.510506</td>\n",
       "      <td>0.424521</td>\n",
       "      <td>0.536385</td>\n",
       "      <td>0.492927</td>\n",
       "      <td>0.570866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825437</th>\n",
       "      <td>0.296025</td>\n",
       "      <td>0.372686</td>\n",
       "      <td>0.561898</td>\n",
       "      <td>0.500679</td>\n",
       "      <td>0.499825</td>\n",
       "      <td>0.499260</td>\n",
       "      <td>0.496063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         acc_rs_x  acc_rs_y  acc_rs_z  gyro_rs_x  gyro_rs_y  gyro_rs_z  \\\n",
       "1660736  0.251408  0.509102  0.509590   0.499626   0.498985   0.499489   \n",
       "1771477  0.119692  0.435248  0.274540   0.297154   0.829694   0.473777   \n",
       "84694    0.253178  0.471687  0.481453   0.499931   0.499901   0.499138   \n",
       "934543   0.000000  0.210330  0.510506   0.424521   0.536385   0.492927   \n",
       "825437   0.296025  0.372686  0.561898   0.500679   0.499825   0.499260   \n",
       "\n",
       "            EMG_r  \n",
       "1660736  0.500000  \n",
       "1771477  0.385827  \n",
       "84694    0.476378  \n",
       "934543   0.570866  \n",
       "825437   0.496063  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = X_train.values\n",
    "test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is our input placeholder\n",
    "input_layer = Input(shape=(7,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(3, activation='relu')(input_layer)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(7, activation='sigmoid')(encoded)\n",
    "\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "decoder_input = Input(shape=(3,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "decoder = Model(decoder_input, decoder_layer(decoder_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1752851 samples, validate on 359018 samples\n",
      "Epoch 1/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0088 - val_loss: 0.0087\n",
      "Epoch 2/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0087 - val_loss: 0.0087\n",
      "Epoch 3/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0086 - val_loss: 0.0086\n",
      "Epoch 4/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0086 - val_loss: 0.0085\n",
      "Epoch 5/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0085 - val_loss: 0.0085\n",
      "Epoch 6/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 7/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 8/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 9/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 10/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 11/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 12/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0081 - val_loss: 0.0081\n",
      "Epoch 13/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 14/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 15/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 16/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 17/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0079 - val_loss: 0.0079\n",
      "Epoch 18/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0079 - val_loss: 0.0078\n",
      "Epoch 19/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 20/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 21/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 22/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 23/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 24/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 25/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 26/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 27/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 28/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 29/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 30/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 31/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 32/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 33/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 34/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 35/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 36/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0074 - val_loss: 0.0074\n",
      "Epoch 37/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 38/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 39/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 40/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 41/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 42/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 43/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 44/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 45/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 46/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 47/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 48/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 49/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 50/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 51/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 52/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 53/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 54/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 55/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 56/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0069 - val_loss: 0.0068\n",
      "Epoch 57/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 58/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 59/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 60/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 61/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 62/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 63/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 64/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 65/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 66/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 67/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 68/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 69/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 70/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 71/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 72/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0061 - val_loss: 0.0061\n",
      "Epoch 73/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 74/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 75/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 76/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 77/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 78/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 79/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0058 - val_loss: 0.0057\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752851/1752851 [==============================] - 18s - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 81/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 82/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 83/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0056 - val_loss: 0.0056\n",
      "Epoch 84/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 85/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 86/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 87/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0055 - val_loss: 0.0055\n",
      "Epoch 88/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 89/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 90/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 91/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 92/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 93/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 94/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 95/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 96/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 97/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 98/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 99/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 100/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 101/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 102/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 103/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 104/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 105/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 106/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 107/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 108/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 109/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 110/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 111/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 112/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 113/1000\n",
      "1750784/1752851 [============================>.] - ETA: 0s - loss: 0.0051\n",
      "Epoch 00112: reducing learning rate to 0.0009999999776482583.\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 114/1000\n",
      "1752851/1752851 [==============================] - 17s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 115/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 116/1000\n",
      "1752851/1752851 [==============================] - 17s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 117/1000\n",
      "1752851/1752851 [==============================] - 17s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 118/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 119/1000\n",
      "1752851/1752851 [==============================] - 17s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 120/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 121/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 122/1000\n",
      "1752851/1752851 [==============================] - 17s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 123/1000\n",
      "1751040/1752851 [============================>.] - ETA: 0s - loss: 0.0051\n",
      "Epoch 00122: reducing learning rate to 9.999999310821295e-05.\n",
      "1752851/1752851 [==============================] - 17s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 124/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 125/1000\n",
      "1752851/1752851 [==============================] - 17s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 126/1000\n",
      "1752851/1752851 [==============================] - 17s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 127/1000\n",
      "1752851/1752851 [==============================] - 17s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 128/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 129/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 130/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 131/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 132/1000\n",
      "1752851/1752851 [==============================] - 17s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 133/1000\n",
      "1747968/1752851 [============================>.] - ETA: 0s - loss: 0.0051\n",
      "Epoch 00132: reducing learning rate to 9.999999019782991e-06.\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 134/1000\n",
      "1752851/1752851 [==============================] - 17s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 135/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 136/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 137/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 138/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 139/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 140/1000\n",
      "1752851/1752851 [==============================] - 17s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 141/1000\n",
      "1752851/1752851 [==============================] - 17s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 142/1000\n",
      "1752851/1752851 [==============================] - 18s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 143/1000\n",
      "1749760/1752851 [============================>.] - ETA: 0s - loss: 0.0051\n",
      "Epoch 00142: reducing learning rate to 9.99999883788405e-07.\n",
      "1752851/1752851 [==============================] - 17s - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 00142: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "ae_history = autoencoder.fit(train, train,\n",
    "                epochs=1000,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(test, test),\n",
    "                callbacks=[\n",
    "                    TensorBoard(log_dir='./logs/one_l_ae'),\n",
    "                    ReduceLROnPlateau(verbose=1),\n",
    "                    EarlyStopping(monitor='val_loss', min_delta=0.000001, patience=20, verbose=1, mode='auto'),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DF.values\n",
    "\n",
    "optimal_features = encoder.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2110720/2111869 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0051043889114447179"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.evaluate(X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2111296/2111869 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0051043889114447179"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.evaluate(optimal_features, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.save('/output/autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder.save('/output/encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder.save('/output/decoder.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
